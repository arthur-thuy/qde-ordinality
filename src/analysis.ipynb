{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import re\n",
    "\n",
    "# related third party imports\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import structlog\n",
    "\n",
    "# local application/library specific imports\n",
    "from tools.configurator import (\n",
    "    get_configs_out,\n",
    "    get_config_ids,\n",
    ")\n",
    "from tools.constants import OutputType, EXCLUDE_METRICS\n",
    "from tools.analyzer import (\n",
    "    print_table_from_dict,\n",
    "    get_train_logs,\n",
    "    get_label_map,\n",
    "    get_single_pred_label,\n",
    "    merge_all_results,\n",
    "    compute_avg_confusion_matrix,\n",
    "    compute_avg_rps_per_level,\n",
    "    get_results_dict,\n",
    "    reorder_config_ids,\n",
    "    compute_rank_inconsistencies,\n",
    "    get_logit_params_history,\n",
    ")\n",
    "from tools.plotter import (\n",
    "    plot_history,\n",
    "    plot_violinplot,\n",
    "    activate_latex,\n",
    "    deactivate_latex,\n",
    "    plot_confusion_matrix,\n",
    "    plot_rank_inconsistencies,\n",
    "    plot_cutpoints_history,\n",
    "    plot_bias_history,\n",
    ")\n",
    "\n",
    "logger = structlog.get_logger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### INPUTS #####\n",
    "EXP_NAME = (\n",
    "    # RACE++\n",
    "    # \"race_pp_bert_bal_rps_20250517\"\n",
    "    \"race_pp_bert_logit_20250522\"\n",
    "\n",
    "    # ARC\n",
    "    # \"arc_bert_bal_rps_20250518\"\n",
    "    # \"arc_bert_logit_20250521\"\n",
    ")\n",
    "CONFIG_ID = \"bert_ordinal_logit_SL512_BALFalse_LR0.000029_WD0.048_FRFalse_ESTrue\"  # TODO: select from config_ids\n",
    "SANS_SERIF = True\n",
    "PRINT_PAPER = False  # False  #\n",
    "LEGEND_EXACT = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG2LEGEND_DICT = {\n",
    "    \"random_regression\": \"Random baseline\",\n",
    "    \"majority_regression\": \"Majority baseline\",\n",
    "    \"bert_regression\": \"BERT - Regression\",\n",
    "    \"bert_classification\": \"BERT - Classification\",\n",
    "    \"bert_ordinal_or_nn\": \"BERT - Ordinal OR-NN\",\n",
    "    \"bert_ordinal_coral\": \"BERT - Ordinal CORAL\",\n",
    "    \"bert_ordinal_corn\": \"BERT - Ordinal CORN\",\n",
    "    \"bert_ordinal_logit\": \"BERT - Ordinal Logit\",\n",
    "}\n",
    "\n",
    "legend_kwargs = {\"config2legend\": CONFIG2LEGEND_DICT, \"legend_exact\": LEGEND_EXACT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configs = get_configs_out(EXP_NAME)\n",
    "config_ids = get_config_ids(configs)\n",
    "config_dict = {config_id: cfg for config_id, cfg in zip(config_ids, configs)}\n",
    "\n",
    "# reorder config_ids according to CONFIG2LEGEND_DICT keys\n",
    "config_ids = reorder_config_ids(config_ids, CONFIG2LEGEND_DICT)\n",
    "pprint(config_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge results for all configs\n",
    "run_id_dict = merge_all_results(EXP_NAME, config_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set performance\n",
    "### Aggregated over levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = get_results_dict(\n",
    "    exp_name=EXP_NAME,\n",
    "    config_ids=config_ids,\n",
    "    run_id=None,\n",
    ")\n",
    "print_table_from_dict(\n",
    "    eval_dict=results_dict,\n",
    "    exp_name=EXP_NAME,\n",
    "    exclude_metrics=EXCLUDE_METRICS,\n",
    "    decimals=3,\n",
    "    **legend_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RPS per level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rps_agg = compute_avg_rps_per_level(\n",
    "    exp_name=EXP_NAME,\n",
    "    config_ids=config_ids,\n",
    "    run_id=None,\n",
    "    config_dict=config_dict,\n",
    ")\n",
    "print_table_from_dict(\n",
    "    eval_dict=rps_agg,\n",
    "    exp_name=EXP_NAME,\n",
    "    exclude_metrics=[],\n",
    "    **legend_kwargs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG_ID in config_ids:\n",
    "    for run_id in run_id_dict[CONFIG_ID]:\n",
    "        logger.info(f\"Plotting history\", run_id=run_id)\n",
    "        train_log, lines, eval_results = get_train_logs(\n",
    "            exp_name=EXP_NAME, config_id=CONFIG_ID, run_id=run_id\n",
    "        )\n",
    "        plot_history(lines, metric=\"eval_bal_rps\")  # NOTE: metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if OutputType.ORD_LOGIT in CONFIG_ID:\n",
    "    for run_id in run_id_dict[CONFIG_ID]:\n",
    "        params_history = get_logit_params_history(\n",
    "            exp_name=EXP_NAME, config_id=CONFIG_ID, run_id=run_id\n",
    "        )\n",
    "        plot_cutpoints_history(params_history)\n",
    "        plot_bias_history(params_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "# CONFIG_ID = USE FROM ABOVE\n",
    "RUN_ID = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for every config_id\n",
    "for config_id in config_ids:\n",
    "    label_map = get_label_map(EXP_NAME, config_id)\n",
    "    avg_conf_matrix = compute_avg_confusion_matrix(\n",
    "        exp_name=EXP_NAME,\n",
    "        config_id=config_id,\n",
    "        run_id=RUN_ID,\n",
    "        int2label=label_map,\n",
    "        config_dict=config_dict,\n",
    "        normalize=\"true\",\n",
    "    )\n",
    "    plot_confusion_matrix(\n",
    "        conf_matrix=avg_conf_matrix,\n",
    "        int2label=label_map,\n",
    "        config_id=config_id,\n",
    "        **legend_kwargs,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "    ########\n",
    "    # plot for every config_id\n",
    "    for config_id in config_ids:\n",
    "        label_map = get_label_map(EXP_NAME, config_id)\n",
    "        dataset_name = config_dict[CONFIG_ID][\"LOADER\"][\"NAME\"]\n",
    "        avg_conf_matrix = compute_avg_confusion_matrix(\n",
    "            exp_name=EXP_NAME,\n",
    "            config_id=config_id,\n",
    "            run_id=RUN_ID,\n",
    "            int2label=label_map,\n",
    "            config_dict=config_dict,\n",
    "            normalize=\"true\",\n",
    "        )\n",
    "        savefig_kwargs = {\n",
    "            \"fname\": os.path.join(\n",
    "                \"output\", EXP_NAME, \"figures\", f\"confusion_{dataset_name}_{config_id}.pdf\"\n",
    "            )\n",
    "        }\n",
    "        plot_confusion_matrix(\n",
    "            conf_matrix=avg_conf_matrix,\n",
    "            int2label=label_map,\n",
    "            config_id=config_id,\n",
    "            **legend_kwargs,\n",
    "            save=True,\n",
    "            savefig_kwargs=savefig_kwargs,\n",
    "        )\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rank inconsistencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord_types = [OutputType.ORD_OR_NN, OutputType.ORD_CORAL, OutputType.ORD_CORN]\n",
    "for config_id in config_ids:\n",
    "    if any(ord_type in config_id for ord_type in ord_types):\n",
    "        sum_count, count_per_obs = compute_rank_inconsistencies(\n",
    "            exp_name=EXP_NAME,\n",
    "            config_id=config_id,\n",
    "            config_dict=config_dict,\n",
    "            run_id=RUN_ID,\n",
    "        )\n",
    "        print(f\"Total # inconsistencies in test set: {sum_count:.0f}\")\n",
    "        print(f\"Average # inconsistencies per test observation: {np.mean(count_per_obs):.4f}\")\n",
    "        print(f\"# test observations with inconsistencies: {np.sum(count_per_obs > 0)}\")\n",
    "        plot_rank_inconsistencies(count_per_obs, num_classes=config_dict[config_id][\"MODEL\"][\"NUM_LABELS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRINT_PAPER:\n",
    "    for config_id in config_ids:\n",
    "        if OutputType.ORD_OR_NN in config_id:\n",
    "            activate_latex(sans_serif=SANS_SERIF)\n",
    "            ########\n",
    "            sum_count, count_per_obs = compute_rank_inconsistencies(\n",
    "                exp_name=EXP_NAME,\n",
    "                config_id=config_id,\n",
    "                config_dict=config_dict,\n",
    "                run_id=RUN_ID,\n",
    "            )\n",
    "            savename = os.path.join(\n",
    "                \"output\", EXP_NAME, \"figures\", f\"rank_inconsistencies_{config_id}.pdf\"\n",
    "            )\n",
    "            plot_rank_inconsistencies(\n",
    "                count_per_obs,\n",
    "                num_classes=config_dict[config_id][\"MODEL\"][\"NUM_LABELS\"],\n",
    "                savename=savename,\n",
    "            )\n",
    "            ########\n",
    "            deactivate_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qde_ordinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
