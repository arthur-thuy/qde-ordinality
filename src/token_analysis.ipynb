{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard library imports\n",
    "import os\n",
    "import subprocess\n",
    "from typing import Optional\n",
    "\n",
    "# related third party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# local application/library specific imports\n",
    "from tools.utils import activate_latex, deactivate_latex, ensure_dir\n",
    "from data_loader.data_loader import QDET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### INPUTS ######\n",
    "PRINT_PAPER = True\n",
    "SANS_SERIF = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_num_tokens(\n",
    "    input_sentences: ArrayLike, tokenizer: AutoTokenizer\n",
    ") -> np.ndarray:\n",
    "    \"\"\"Computes the number of tokens in each sentence in a list of sentences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_sentences : ArrayLike\n",
    "        List of sentences.\n",
    "    tokenizer : AutoTokenizer\n",
    "        Tokenizer object.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    np.ndarray\n",
    "        Array of number of tokens in each sentence.\n",
    "    \"\"\"\n",
    "    input_ids = tokenizer(input_sentences)[\"input_ids\"]\n",
    "    return np.array([len(sentence) for sentence in input_ids])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_info(num_tokens: ArrayLike) -> None:\n",
    "    \"\"\"Print info about tokens.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_tokens : ArrayLike\n",
    "        Array of number of tokens per sequence.\n",
    "    \"\"\"\n",
    "    print(f\"Mean: {np.mean(num_tokens):.2f}\")\n",
    "    print(f\"Median: {np.median(num_tokens):.2f}\")\n",
    "    print(f\"Max: {np.max(num_tokens)}\")\n",
    "    print(f\"Min: {np.min(num_tokens)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_token_hist(\n",
    "    num_tokens_dict: dict[str, NDArray],\n",
    "    bins: int = 20,\n",
    "    vline: Optional[int] = None,\n",
    "    savename: Optional[str] = None,\n",
    ") -> plt.Axes:\n",
    "    \"\"\"Plots histogram of number of tokens in sentences.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_tokens_dict : dict[str, NDArray]\n",
    "        Dictionary of number of tokens in sentences.\n",
    "    bins : int, optional\n",
    "        Histogram bins, by default 20\n",
    "    vline : Optional[int], optional\n",
    "        Vertical line at some token limit, by default None\n",
    "    savename : Optional[str], optional\n",
    "        Name to save plot to, by default None\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    plt.Axes\n",
    "        Axes object.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5,3))\n",
    "    for name, num_tokens in num_tokens_dict.items():\n",
    "        ax.hist(num_tokens, bins=bins, alpha=0.5, label=name)\n",
    "    if vline:\n",
    "        ax.axvline(vline, color=\"red\", linestyle=\"--\", label=\"512 tokens\")\n",
    "    ax.set_xlabel(\"Number of tokens\")\n",
    "    ax.set_ylabel(\"Frequency\")\n",
    "    ax.legend()\n",
    "    ax.grid(True, linestyle=\"--\")\n",
    "    # get ticks in sans-serif if sans-serif is used\n",
    "    ax.xaxis.get_major_formatter()._usetex = False\n",
    "    ax.yaxis.get_major_formatter()._usetex = False\n",
    "    if savename is not None:\n",
    "        plt.tight_layout()\n",
    "        ensure_dir(os.path.dirname(savename))\n",
    "        plt.savefig(savename)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = QDET(\n",
    "    name=\"arc\",\n",
    "    num_classes=7,\n",
    "    output_type=\"regression\",\n",
    "    small_dev=None,\n",
    "    balanced=True,\n",
    "    seed=42,\n",
    ")\n",
    "arc_dataset = loader.load_all()\n",
    "\n",
    "loader = QDET(\n",
    "    name=\"race_pp\",\n",
    "    num_classes=3,\n",
    "    output_type=\"regression\",\n",
    "    small_dev=None,\n",
    "    balanced=False,\n",
    "    seed=42,\n",
    ")\n",
    "racepp_dataset = loader.load_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ARC - BERT\n",
    "num_tokens_bert_arc = compute_num_tokens(\n",
    "    input_sentences=arc_dataset[\"train\"][\"text\"],\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\"),\n",
    ")\n",
    "\n",
    "# RACE++ - BERT\n",
    "num_tokens_bert_racepp = compute_num_tokens(\n",
    "    input_sentences=racepp_dataset[\"train\"][\"text\"],\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"bert-base-uncased\"),\n",
    ")\n",
    "\n",
    "# ARC - ModernBERT\n",
    "num_tokens_modernbert_arc = compute_num_tokens(\n",
    "    input_sentences=arc_dataset[\"train\"][\"text\"],\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\"),\n",
    ")\n",
    "\n",
    "# RACE++ - ModernBERT\n",
    "num_tokens_modernbert_racepp = compute_num_tokens(\n",
    "    input_sentences=racepp_dataset[\"train\"][\"text\"],\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"answerdotai/ModernBERT-base\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_token_info(num_tokens_bert_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_token_info(num_tokens_bert_racepp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_token_info(num_tokens_modernbert_arc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_token_info(num_tokens_modernbert_racepp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_hist(\n",
    "    num_tokens_dict={\"BERT\": num_tokens_bert_arc, \"ModernBERT\": num_tokens_modernbert_arc},\n",
    "    vline=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_token_hist(\n",
    "    num_tokens_dict={\"BERT\": num_tokens_bert_racepp, \"ModernBERT\": num_tokens_modernbert_racepp},\n",
    "    vline=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PRINT_PAPER:\n",
    "    activate_latex(sans_serif=SANS_SERIF)\n",
    "    ########\n",
    "    plot_token_hist(\n",
    "        num_tokens_dict={\n",
    "            \"BERT\": num_tokens_bert_arc,\n",
    "            \"ModernBERT\": num_tokens_modernbert_arc,\n",
    "        },\n",
    "        vline=512,\n",
    "        savename=os.path.join(\"output\", \"figures\", \"arc_token_hist.pdf\"),\n",
    "    )\n",
    "    ########\n",
    "    plot_token_hist(\n",
    "        num_tokens_dict={\n",
    "            \"BERT\": num_tokens_bert_racepp,\n",
    "            \"ModernBERT\": num_tokens_modernbert_racepp,\n",
    "        },\n",
    "        vline=512,\n",
    "        savename=os.path.join(\"output\", \"figures\", \"racepp_token_hist.pdf\"),\n",
    "    )\n",
    "    ########\n",
    "    deactivate_latex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qde_ordinal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
